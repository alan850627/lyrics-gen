Iteration 10000, batch loss: 0.011956, training accuracy: 0.16000
Iteration 20000, batch loss: 0.011085, training accuracy: 0.26000
Iteration 30000, batch loss: 0.011918, training accuracy: 0.10000
Iteration 40000, batch loss: 0.011041, training accuracy: 0.24000
Iteration 50000, batch loss: 0.011160, training accuracy: 0.20000
Iteration 60000, batch loss: 0.010718, training accuracy: 0.28000
Iteration 70000, batch loss: 0.010820, training accuracy: 0.24000
Iteration 80000, batch loss: 0.011802, training accuracy: 0.26000
Iteration 90000, batch loss: 0.010466, training accuracy: 0.38000
Iteration 100000, batch loss: 0.010907, training accuracy: 0.30000
Iteration 110000, batch loss: 0.010562, training accuracy: 0.28000
Iteration 120000, batch loss: 0.009975, training accuracy: 0.32000
Iteration 130000, batch loss: 0.010518, training accuracy: 0.32000
Iteration 140000, batch loss: 0.009293, training accuracy: 0.36000
Iteration 150000, batch loss: 0.010522, training accuracy: 0.34000
Iteration 160000, batch loss: 0.009994, training accuracy: 0.36000
Iteration 170000, batch loss: 0.009639, training accuracy: 0.28000
Iteration 180000, batch loss: 0.010431, training accuracy: 0.30000
Iteration 190000, batch loss: 0.009777, training accuracy: 0.36000
Iteration 200000, batch loss: 0.009329, training accuracy: 0.42000
Iteration 210000, batch loss: 0.009400, training accuracy: 0.40000
Iteration 220000, batch loss: 0.009607, training accuracy: 0.44000
Iteration 230000, batch loss: 0.009693, training accuracy: 0.50000
Iteration 240000, batch loss: 0.009225, training accuracy: 0.40000
Iteration 250000, batch loss: 0.009119, training accuracy: 0.44000
Iteration 260000, batch loss: 0.008802, training accuracy: 0.42000
Iteration 270000, batch loss: 0.008717, training accuracy: 0.44000
Iteration 280000, batch loss: 0.009174, training accuracy: 0.38000
Iteration 290000, batch loss: 0.010485, training accuracy: 0.26000
Iteration 300000, batch loss: 0.008973, training accuracy: 0.44000
Iteration 310000, batch loss: 0.007322, training accuracy: 0.60000
Iteration 320000, batch loss: 0.008580, training accuracy: 0.46000
Iteration 330000, batch loss: 0.009674, training accuracy: 0.34000
Iteration 340000, batch loss: 0.008174, training accuracy: 0.46000
Iteration 350000, batch loss: 0.008444, training accuracy: 0.48000
Iteration 360000, batch loss: 0.009353, training accuracy: 0.40000
Iteration 370000, batch loss: 0.010437, training accuracy: 0.30000
Iteration 380000, batch loss: 0.008464, training accuracy: 0.48000
Iteration 390000, batch loss: 0.008129, training accuracy: 0.48000
Iteration 400000, batch loss: 0.008048, training accuracy: 0.50000
Iteration 410000, batch loss: 0.008981, training accuracy: 0.54000
Iteration 420000, batch loss: 0.008884, training accuracy: 0.46000
Iteration 430000, batch loss: 0.008705, training accuracy: 0.40000
Iteration 440000, batch loss: 0.008120, training accuracy: 0.50000
Iteration 450000, batch loss: 0.007254, training accuracy: 0.62000
Iteration 460000, batch loss: 0.008138, training accuracy: 0.46000
Iteration 470000, batch loss: 0.007884, training accuracy: 0.44000
Iteration 480000, batch loss: 0.008895, training accuracy: 0.48000
Iteration 490000, batch loss: 0.008424, training accuracy: 0.50000
Iteration 500000, batch loss: 0.008759, training accuracy: 0.50000
Iteration 510000, batch loss: 0.007496, training accuracy: 0.52000
Iteration 520000, batch loss: 0.008769, training accuracy: 0.42000
Iteration 530000, batch loss: 0.007758, training accuracy: 0.48000
Iteration 540000, batch loss: 0.008679, training accuracy: 0.38000
Iteration 550000, batch loss: 0.009376, training accuracy: 0.44000
Iteration 560000, batch loss: 0.007360, training accuracy: 0.56000
Iteration 570000, batch loss: 0.009332, training accuracy: 0.44000
Iteration 580000, batch loss: 0.007464, training accuracy: 0.58000
Iteration 590000, batch loss: 0.008567, training accuracy: 0.46000
Iteration 600000, batch loss: 0.008210, training accuracy: 0.48000
Iteration 610000, batch loss: 0.007898, training accuracy: 0.50000
Iteration 620000, batch loss: 0.008466, training accuracy: 0.54000
Iteration 630000, batch loss: 0.008318, training accuracy: 0.50000
Iteration 640000, batch loss: 0.008370, training accuracy: 0.40000
Iteration 650000, batch loss: 0.007394, training accuracy: 0.64000
Iteration 660000, batch loss: 0.007068, training accuracy: 0.52000
Iteration 670000, batch loss: 0.009338, training accuracy: 0.36000
Iteration 680000, batch loss: 0.007554, training accuracy: 0.48000
Iteration 690000, batch loss: 0.006949, training accuracy: 0.64000
Iteration 700000, batch loss: 0.007287, training accuracy: 0.60000
Iteration 710000, batch loss: 0.006087, training accuracy: 0.68000
Iteration 720000, batch loss: 0.006624, training accuracy: 0.62000
Iteration 730000, batch loss: 0.006926, training accuracy: 0.56000
Iteration 740000, batch loss: 0.006333, training accuracy: 0.62000
Iteration 750000, batch loss: 0.006939, training accuracy: 0.60000
Iteration 760000, batch loss: 0.005521, training accuracy: 0.74000
Iteration 770000, batch loss: 0.007786, training accuracy: 0.56000
Iteration 780000, batch loss: 0.006754, training accuracy: 0.58000
Iteration 790000, batch loss: 0.007193, training accuracy: 0.54000
Iteration 800000, batch loss: 0.007164, training accuracy: 0.54000
Iteration 810000, batch loss: 0.005778, training accuracy: 0.68000
Iteration 820000, batch loss: 0.007515, training accuracy: 0.54000
Iteration 830000, batch loss: 0.007326, training accuracy: 0.54000
Iteration 840000, batch loss: 0.006645, training accuracy: 0.58000
Iteration 850000, batch loss: 0.007324, training accuracy: 0.58000
Iteration 860000, batch loss: 0.005539, training accuracy: 0.68000
Iteration 870000, batch loss: 0.006142, training accuracy: 0.58000
Iteration 880000, batch loss: 0.005217, training accuracy: 0.68000
Iteration 890000, batch loss: 0.005608, training accuracy: 0.68000
Iteration 900000, batch loss: 0.005706, training accuracy: 0.70000
Iteration 910000, batch loss: 0.006535, training accuracy: 0.62000
Iteration 920000, batch loss: 0.006165, training accuracy: 0.58000
Iteration 930000, batch loss: 0.004677, training accuracy: 0.78000
Iteration 940000, batch loss: 0.006618, training accuracy: 0.58000
Iteration 950000, batch loss: 0.005524, training accuracy: 0.64000
Iteration 960000, batch loss: 0.006000, training accuracy: 0.64000
Iteration 970000, batch loss: 0.004482, training accuracy: 0.76000
Iteration 980000, batch loss: 0.005566, training accuracy: 0.70000
Iteration 990000, batch loss: 0.005480, training accuracy: 0.66000
Iteration 1000000, batch loss: 0.006961, training accuracy: 0.56000
Iteration 1010000, batch loss: 0.004469, training accuracy: 0.76000
Iteration 1020000, batch loss: 0.004716, training accuracy: 0.68000
Iteration 1030000, batch loss: 0.005346, training accuracy: 0.68000
Iteration 1040000, batch loss: 0.005157, training accuracy: 0.66000
Iteration 1050000, batch loss: 0.005838, training accuracy: 0.66000
Iteration 1060000, batch loss: 0.004629, training accuracy: 0.72000
Iteration 1070000, batch loss: 0.005566, training accuracy: 0.64000
Iteration 1080000, batch loss: 0.003911, training accuracy: 0.78000
Iteration 1090000, batch loss: 0.005472, training accuracy: 0.68000
Iteration 1100000, batch loss: 0.004569, training accuracy: 0.72000
Iteration 1110000, batch loss: 0.004695, training accuracy: 0.70000
Iteration 1120000, batch loss: 0.004084, training accuracy: 0.78000
Iteration 1130000, batch loss: 0.004315, training accuracy: 0.72000
Iteration 1140000, batch loss: 0.005083, training accuracy: 0.68000
Iteration 1150000, batch loss: 0.004288, training accuracy: 0.72000
Iteration 1160000, batch loss: 0.003947, training accuracy: 0.82000
Iteration 1170000, batch loss: 0.003127, training accuracy: 0.86000
Iteration 1180000, batch loss: 0.003963, training accuracy: 0.76000
Iteration 1190000, batch loss: 0.005333, training accuracy: 0.64000
Iteration 1200000, batch loss: 0.004565, training accuracy: 0.72000
Iteration 1210000, batch loss: 0.004143, training accuracy: 0.76000
Iteration 1220000, batch loss: 0.004623, training accuracy: 0.70000
Iteration 1230000, batch loss: 0.003857, training accuracy: 0.80000
Iteration 1240000, batch loss: 0.004067, training accuracy: 0.74000
Iteration 1250000, batch loss: 0.003801, training accuracy: 0.74000
Iteration 1260000, batch loss: 0.004440, training accuracy: 0.72000
Iteration 1270000, batch loss: 0.003461, training accuracy: 0.74000
Iteration 1280000, batch loss: 0.002997, training accuracy: 0.82000
Iteration 1290000, batch loss: 0.003299, training accuracy: 0.82000
Iteration 1300000, batch loss: 0.003907, training accuracy: 0.74000
Iteration 1310000, batch loss: 0.005570, training accuracy: 0.66000
Iteration 1320000, batch loss: 0.003800, training accuracy: 0.80000
Iteration 1330000, batch loss: 0.003605, training accuracy: 0.82000
Iteration 1340000, batch loss: 0.003818, training accuracy: 0.74000
Iteration 1350000, batch loss: 0.002976, training accuracy: 0.86000
Iteration 1360000, batch loss: 0.003736, training accuracy: 0.78000
Iteration 1370000, batch loss: 0.002709, training accuracy: 0.84000
Iteration 1380000, batch loss: 0.002945, training accuracy: 0.86000
Iteration 1390000, batch loss: 0.003256, training accuracy: 0.86000
Iteration 1400000, batch loss: 0.003831, training accuracy: 0.76000
Iteration 1410000, batch loss: 0.003161, training accuracy: 0.86000
Iteration 1420000, batch loss: 0.004356, training accuracy: 0.76000
Iteration 1430000, batch loss: 0.004035, training accuracy: 0.76000
Iteration 1440000, batch loss: 0.002765, training accuracy: 0.88000
Iteration 1450000, batch loss: 0.003623, training accuracy: 0.80000
Iteration 1460000, batch loss: 0.002272, training accuracy: 0.86000
Iteration 1470000, batch loss: 0.003051, training accuracy: 0.86000
Iteration 1480000, batch loss: 0.002202, training accuracy: 0.90000
Iteration 1490000, batch loss: 0.002482, training accuracy: 0.88000
Iteration 1500000, batch loss: 0.004013, training accuracy: 0.76000
Iteration 1510000, batch loss: 0.002589, training accuracy: 0.86000
Iteration 1520000, batch loss: 0.002449, training accuracy: 0.90000
Iteration 1530000, batch loss: 0.003120, training accuracy: 0.82000
Iteration 1540000, batch loss: 0.003511, training accuracy: 0.78000
Iteration 1550000, batch loss: 0.002535, training accuracy: 0.92000
Iteration 1560000, batch loss: 0.003009, training accuracy: 0.80000
Iteration 1570000, batch loss: 0.002323, training accuracy: 0.90000
Iteration 1580000, batch loss: 0.002437, training accuracy: 0.88000
Iteration 1590000, batch loss: 0.001977, training accuracy: 0.90000
Iteration 1600000, batch loss: 0.002511, training accuracy: 0.88000
Iteration 1610000, batch loss: 0.002171, training accuracy: 0.90000
Iteration 1620000, batch loss: 0.003597, training accuracy: 0.86000
Iteration 1630000, batch loss: 0.003391, training accuracy: 0.82000
Iteration 1640000, batch loss: 0.002166, training accuracy: 0.90000
Iteration 1650000, batch loss: 0.002108, training accuracy: 0.90000
Iteration 1660000, batch loss: 0.002094, training accuracy: 0.88000
Iteration 1670000, batch loss: 0.002727, training accuracy: 0.86000
Iteration 1680000, batch loss: 0.002882, training accuracy: 0.82000
Iteration 1690000, batch loss: 0.002108, training accuracy: 0.88000
Iteration 1700000, batch loss: 0.002499, training accuracy: 0.88000
Iteration 1710000, batch loss: 0.001811, training accuracy: 0.92000
Iteration 1720000, batch loss: 0.002054, training accuracy: 0.94000
Iteration 1730000, batch loss: 0.002502, training accuracy: 0.86000
Iteration 1740000, batch loss: 0.003039, training accuracy: 0.84000
Iteration 1750000, batch loss: 0.003501, training accuracy: 0.82000
Iteration 1760000, batch loss: 0.001914, training accuracy: 0.90000
Iteration 1770000, batch loss: 0.001854, training accuracy: 0.92000
Iteration 1780000, batch loss: 0.003046, training accuracy: 0.86000
Iteration 1790000, batch loss: 0.002002, training accuracy: 0.90000
Iteration 1800000, batch loss: 0.001556, training accuracy: 0.94000
Iteration 1810000, batch loss: 0.002963, training accuracy: 0.86000
Iteration 1820000, batch loss: 0.001922, training accuracy: 0.92000
Iteration 1830000, batch loss: 0.002272, training accuracy: 0.88000
Iteration 1840000, batch loss: 0.002868, training accuracy: 0.84000
Iteration 1850000, batch loss: 0.002233, training accuracy: 0.88000
Iteration 1860000, batch loss: 0.002337, training accuracy: 0.88000
Iteration 1870000, batch loss: 0.001512, training accuracy: 0.94000
Iteration 1880000, batch loss: 0.001979, training accuracy: 0.90000
Iteration 1890000, batch loss: 0.002197, training accuracy: 0.86000
Iteration 1900000, batch loss: 0.001857, training accuracy: 0.94000
Iteration 1910000, batch loss: 0.001945, training accuracy: 0.92000
Iteration 1920000, batch loss: 0.002524, training accuracy: 0.86000
Iteration 1930000, batch loss: 0.001710, training accuracy: 0.90000
Iteration 1940000, batch loss: 0.001603, training accuracy: 0.98000
Iteration 1950000, batch loss: 0.002007, training accuracy: 0.90000
Iteration 1960000, batch loss: 0.001283, training accuracy: 0.96000
Iteration 1970000, batch loss: 0.002007, training accuracy: 0.88000
Iteration 1980000, batch loss: 0.003026, training accuracy: 0.86000
Iteration 1990000, batch loss: 0.002659, training accuracy: 0.86000
Iteration 2000000, batch loss: 0.002152, training accuracy: 0.92000
Iteration 2010000, batch loss: 0.001729, training accuracy: 0.94000
Iteration 2020000, batch loss: 0.002136, training accuracy: 0.88000
Iteration 2030000, batch loss: 0.001562, training accuracy: 0.96000
Iteration 2040000, batch loss: 0.002371, training accuracy: 0.86000
Iteration 2050000, batch loss: 0.002046, training accuracy: 0.88000
Iteration 2060000, batch loss: 0.002120, training accuracy: 0.90000
Iteration 2070000, batch loss: 0.002929, training accuracy: 0.82000
Iteration 2080000, batch loss: 0.002209, training accuracy: 0.90000
Iteration 2090000, batch loss: 0.001046, training accuracy: 0.94000
Iteration 2100000, batch loss: 0.002552, training accuracy: 0.84000
Iteration 2110000, batch loss: 0.001737, training accuracy: 0.92000
Iteration 2120000, batch loss: 0.001610, training accuracy: 0.92000
Iteration 2130000, batch loss: 0.003212, training accuracy: 0.80000
Iteration 2140000, batch loss: 0.002397, training accuracy: 0.84000
Iteration 2150000, batch loss: 0.002356, training accuracy: 0.82000
Iteration 2160000, batch loss: 0.002609, training accuracy: 0.92000
Iteration 2170000, batch loss: 0.002005, training accuracy: 0.94000
Iteration 2180000, batch loss: 0.001712, training accuracy: 0.90000
Iteration 2190000, batch loss: 0.001007, training accuracy: 0.96000
Iteration 2200000, batch loss: 0.002279, training accuracy: 0.88000
Iteration 2210000, batch loss: 0.002056, training accuracy: 0.90000
Iteration 2220000, batch loss: 0.001864, training accuracy: 0.92000
Iteration 2230000, batch loss: 0.002701, training accuracy: 0.86000
Iteration 2240000, batch loss: 0.001593, training accuracy: 0.92000
Iteration 2250000, batch loss: 0.001330, training accuracy: 0.96000
Iteration 2260000, batch loss: 0.002172, training accuracy: 0.92000
Iteration 2270000, batch loss: 0.002113, training accuracy: 0.90000
Iteration 2280000, batch loss: 0.001004, training accuracy: 0.96000
Iteration 2290000, batch loss: 0.001811, training accuracy: 0.88000
Iteration 2300000, batch loss: 0.001203, training accuracy: 0.96000
Iteration 2310000, batch loss: 0.001756, training accuracy: 0.96000
Iteration 2320000, batch loss: 0.002060, training accuracy: 0.88000
Iteration 2330000, batch loss: 0.002089, training accuracy: 0.96000
Iteration 2340000, batch loss: 0.001738, training accuracy: 0.94000
Iteration 2350000, batch loss: 0.001887, training accuracy: 0.96000
Iteration 2360000, batch loss: 0.001850, training accuracy: 0.90000
Iteration 2370000, batch loss: 0.001120, training accuracy: 0.96000
Iteration 2380000, batch loss: 0.001868, training accuracy: 0.94000
Iteration 2390000, batch loss: 0.001736, training accuracy: 0.94000
Iteration 2400000, batch loss: 0.001867, training accuracy: 0.96000
Iteration 2410000, batch loss: 0.002096, training accuracy: 0.90000
Iteration 2420000, batch loss: 0.002081, training accuracy: 0.86000
Iteration 2430000, batch loss: 0.001919, training accuracy: 0.90000
Iteration 2440000, batch loss: 0.001530, training accuracy: 0.92000
Iteration 2450000, batch loss: 0.002252, training accuracy: 0.86000
Iteration 2460000, batch loss: 0.001163, training accuracy: 0.94000
Iteration 2470000, batch loss: 0.001828, training accuracy: 0.92000
Iteration 2480000, batch loss: 0.001327, training accuracy: 0.94000
Iteration 2490000, batch loss: 0.001088, training accuracy: 0.96000
Iteration 2500000, batch loss: 0.001598, training accuracy: 0.92000
Iteration 2510000, batch loss: 0.001098, training accuracy: 0.94000
Iteration 2520000, batch loss: 0.002982, training accuracy: 0.80000
Iteration 2530000, batch loss: 0.001680, training accuracy: 0.90000
Iteration 2540000, batch loss: 0.001876, training accuracy: 0.88000
Iteration 2550000, batch loss: 0.001557, training accuracy: 0.92000
Iteration 2560000, batch loss: 0.001179, training accuracy: 0.96000
Iteration 2570000, batch loss: 0.001483, training accuracy: 0.92000
Iteration 2580000, batch loss: 0.002381, training accuracy: 0.84000
Iteration 2590000, batch loss: 0.001191, training accuracy: 0.94000
Iteration 2600000, batch loss: 0.001515, training accuracy: 0.90000
Iteration 2610000, batch loss: 0.000816, training accuracy: 0.98000
Iteration 2620000, batch loss: 0.001180, training accuracy: 0.96000
Iteration 2630000, batch loss: 0.001065, training accuracy: 0.96000
Iteration 2640000, batch loss: 0.001014, training accuracy: 0.98000
Iteration 2650000, batch loss: 0.001327, training accuracy: 0.92000
Iteration 2660000, batch loss: 0.001214, training accuracy: 0.96000
Iteration 2670000, batch loss: 0.001290, training accuracy: 0.94000
Iteration 2680000, batch loss: 0.001331, training accuracy: 0.96000
Iteration 2690000, batch loss: 0.001699, training accuracy: 0.92000
Iteration 2700000, batch loss: 0.000672, training accuracy: 0.98000
Iteration 2710000, batch loss: 0.001531, training accuracy: 0.92000
Iteration 2720000, batch loss: 0.000662, training accuracy: 1.00000
Iteration 2730000, batch loss: 0.001424, training accuracy: 0.92000
Iteration 2740000, batch loss: 0.000443, training accuracy: 1.00000
Iteration 2750000, batch loss: 0.001319, training accuracy: 0.94000
Iteration 2760000, batch loss: 0.001593, training accuracy: 0.90000
Iteration 2770000, batch loss: 0.001075, training accuracy: 0.96000
Iteration 2780000, batch loss: 0.001496, training accuracy: 0.92000
Iteration 2790000, batch loss: 0.001473, training accuracy: 0.90000
Iteration 2800000, batch loss: 0.001098, training accuracy: 0.98000
Iteration 2810000, batch loss: 0.002153, training accuracy: 0.90000
Iteration 2820000, batch loss: 0.001136, training accuracy: 0.94000
Iteration 2830000, batch loss: 0.001619, training accuracy: 0.92000
Iteration 2840000, batch loss: 0.002249, training accuracy: 0.88000
Iteration 2850000, batch loss: 0.001195, training accuracy: 0.94000
Iteration 2860000, batch loss: 0.001524, training accuracy: 0.92000
Iteration 2870000, batch loss: 0.001474, training accuracy: 0.92000
Iteration 2880000, batch loss: 0.001731, training accuracy: 0.92000
Iteration 2890000, batch loss: 0.001801, training accuracy: 0.88000
Iteration 2900000, batch loss: 0.001671, training accuracy: 0.94000
Iteration 2910000, batch loss: 0.001528, training accuracy: 0.94000
Iteration 2920000, batch loss: 0.001008, training accuracy: 0.94000
Iteration 2930000, batch loss: 0.001474, training accuracy: 0.92000
Iteration 2940000, batch loss: 0.001788, training accuracy: 0.92000
Iteration 2950000, batch loss: 0.001568, training accuracy: 0.92000
Iteration 2960000, batch loss: 0.001780, training accuracy: 0.92000
Iteration 2970000, batch loss: 0.000890, training accuracy: 0.98000
Iteration 2980000, batch loss: 0.000701, training accuracy: 0.98000
Iteration 2990000, batch loss: 0.001345, training accuracy: 0.96000
Iteration 3000000, batch loss: 0.001755, training accuracy: 0.94000
Iteration 3010000, batch loss: 0.001649, training accuracy: 0.96000
Iteration 3020000, batch loss: 0.001541, training accuracy: 0.94000
Iteration 3030000, batch loss: 0.001224, training accuracy: 0.98000
Iteration 3040000, batch loss: 0.001580, training accuracy: 0.92000
Iteration 3050000, batch loss: 0.001178, training accuracy: 0.94000
Iteration 3060000, batch loss: 0.000985, training accuracy: 0.96000
Iteration 3070000, batch loss: 0.001740, training accuracy: 0.88000
Iteration 3080000, batch loss: 0.001502, training accuracy: 0.90000
Iteration 3090000, batch loss: 0.001721, training accuracy: 0.88000
Iteration 3100000, batch loss: 0.001056, training accuracy: 0.96000
Iteration 3110000, batch loss: 0.001798, training accuracy: 0.88000
Iteration 3120000, batch loss: 0.000963, training accuracy: 0.98000
Iteration 3130000, batch loss: 0.000527, training accuracy: 1.00000
Iteration 3140000, batch loss: 0.001518, training accuracy: 0.92000
Iteration 3150000, batch loss: 0.000950, training accuracy: 0.96000
Iteration 3160000, batch loss: 0.000658, training accuracy: 0.98000
Iteration 3170000, batch loss: 0.001049, training accuracy: 0.96000
Iteration 3180000, batch loss: 0.000841, training accuracy: 0.98000
Iteration 3190000, batch loss: 0.001628, training accuracy: 0.94000
